{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex44lel/latexify1.0/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PACE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0,'/home/hice1/yqiu343/.local/lib/python3.9/site-packages')\n",
        "# sys.path.insert(0, '/home/hice1/yqiu343/scratch/lib/python3.9/site-packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PACE ships an older version of torchvision that does not have swin_v2\n",
        "!pip3 install torchvision -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relied by torcheval. Need to upgrade to override the default.\n",
        "# Otherwise, OSError: libtorch_cuda_cpp.so:\n",
        "# cannot open shared object file: No such file or directory\n",
        "!pip3 install torchaudio -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# release cache storage (if needed)\n",
        "!pip3 cache purge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKBStJf2VysW"
      },
      "source": [
        "### GitFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKbnsXaH_tFx",
        "outputId": "8b5406f6-a964-4325-ebf1-44bda31e8ba4"
      },
      "outputs": [],
      "source": [
        "!apt-get install git-lfs\n",
        "!pip install torcheval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kmOrx7xgLHZ",
        "outputId": "ace03095-86d1-4bb2-ac87-f5f9fadda5e0"
      },
      "outputs": [],
      "source": [
        "!git init\n",
        "!git config --global user.name \"alex44lel\"\n",
        "!git config --global user.email \"alejandroch2011@gmail.com\"\n",
        "username = 'alex44lel'\n",
        "git_token = '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'\n",
        "repository = 'latexify1.0'\n",
        "!git remote add origin https://{git_token}@github.com/{username}/{repository}.git\n",
        "!git branch -M main\n",
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_5ow3urguQ8",
        "outputId": "521702c5-c722-43c4-e9e1-ef47491e0e02"
      },
      "outputs": [],
      "source": [
        "!git add .\n",
        "!git commit -m \"train FIX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T7b8BtKw7dT",
        "outputId": "a15be70a-87cd-455f-e7f6-82ceb36e0a23"
      },
      "outputs": [],
      "source": [
        "!git push origin main --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4_ONoFPisR14"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEDYfjJfXTkh",
        "outputId": "aeebc358-eec7-4899-9296-18815f881b7c"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "!sh ./scripts/get_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxkZ1XGPAAfO"
      },
      "outputs": [],
      "source": [
        "!cp images-post.zip ./data/dataset5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-sVdbwSAiz1",
        "outputId": "c63f374f-9cde-4f28-9fc2-e5d5991e3cf3"
      },
      "outputs": [],
      "source": [
        "%cd data/dataset5\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSd45ZRFAHlQ",
        "outputId": "ec3f9ab0-d5a5-470e-8154-0c2c07ba8fd1"
      },
      "outputs": [],
      "source": [
        "!unzip images-post.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9bC5FxpAuBq",
        "outputId": "63077aec-60ef-4435-8726-761a6ba0849f"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSCHuQ87w5Tj"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8QVyUN632T4"
      },
      "source": [
        "The I2L140k dataset is made from the dataset Im2Latex-90k, the following process was made to get the final dataset that was used (https://github.com/untrix/im2latex/tree/master/src/preprocessing):\n",
        "\n",
        "0)\n",
        "\n",
        "1)\n",
        "\n",
        "2)\n",
        "\n",
        "3)\n",
        "\n",
        "4)\n",
        "\n",
        "5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MlwkEYbzr6KB"
      },
      "outputs": [],
      "source": [
        "from src.data_handler import Im2LatexDataHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVE9kYMhvBkf",
        "outputId": "1d382aa4-1f7d-4243-8526-e6f462959f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11 11\n"
          ]
        }
      ],
      "source": [
        "handler = Im2LatexDataHandler(train_percentage=0.1)\n",
        "df_combined, y_combined, tuple_len = handler.load_data_and_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctVe4kpg7G3c"
      },
      "source": [
        "Here goes an explanation of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK2B7de0297w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def count_latex_symbols(df):\n",
        "\n",
        "    patterns = {\n",
        "        'integral': r'\\\\int',\n",
        "        'infinity': r'\\\\infty',\n",
        "        'sum': r'\\\\sum',\n",
        "        'product': r'\\\\prod',\n",
        "        'square root': r'\\\\sqrt',\n",
        "        'factorial': r'\\\\!',\n",
        "        'open_arrow': r'\\\\rightarrow',\n",
        "        'close_arrow': r'\\\\leftarrow',\n",
        "        'fraction': r'\\\\frac',\n",
        "        'summation': r'\\\\sum',\n",
        "        'product': r'\\\\prod',\n",
        "        'equivalent': r'\\\\equiv',\n",
        "        'combinations': r'\\\\binom',\n",
        "        # Don't work yet\n",
        "        'cos': r'\\\\cos',\n",
        "        'sin': r'\\\\sin',\n",
        "        'tan': r'\\\\tan',\n",
        "        'natural logarithm': r'\\\\ln',\n",
        "        'derivative': r'\\\\mathrm',\n",
        "        'limit': r'\\\\lim',\n",
        "        'log': r'\\\\log'\n",
        "    }\n",
        "\n",
        "    symbol_counter = {key: 0 for key in patterns.keys()}\n",
        "\n",
        "    for entry in df['latex_ascii']:\n",
        "        for key, pattern in patterns.items():\n",
        "            matches = re.findall(pattern, entry, flags=re.DOTALL)\n",
        "            symbol_counter[key] += len(matches)\n",
        "\n",
        "    return symbol_counter\n",
        "\n",
        "symbol_counts = count_latex_symbols(df_train)\n",
        "symbol_counts = count_latex_symbols(df_test)\n",
        "symbol_counts = count_latex_symbols(df_valid)\n",
        "print(symbol_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkFOoGXgjs5h"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbwwsWQP6PPS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A6Sq6ITWjrw8"
      },
      "outputs": [],
      "source": [
        "from src.data_loader import CustomLatexDataset, get_data_loaders\n",
        "from src.train import train, get_model\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqrVYvubbx2j"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "PNrCafuhwSvK",
        "outputId": "78f4cee1-4489-42b9-d23f-2c520e355365"
      },
      "outputs": [],
      "source": [
        "from src.train import train, get_model\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "encoder_names = [\n",
        "    \"resnet18\",\n",
        "    \"resnet34\",\n",
        "    \"resnet50\",\n",
        "    \"resnet101\",\n",
        "    \"resnet152\",\n",
        "    \"convnext_tiny\",\n",
        "    \"convnext_small\",\n",
        "    \"convnext_base\",\n",
        "    \"convnext_large\",\n",
        "    \"swin_v2_t\",\n",
        "    \"swin_v2_s\",\n",
        "    \"swin_v2_b\"\n",
        "]\n",
        "\n",
        "decoder_names = [\n",
        "    \"gpt\",\n",
        "    \"transformer\"\n",
        "]\n",
        "\n",
        "for enc_name in encoder_names:\n",
        "      print(f'{enc_name}_{dec_name}')\n",
        "      model, tokenizer = get_model(enc_name, \"dec_name\", {}, {}, {})\n",
        "\n",
        "      train_loader = get_data_loaders(\n",
        "          df_combined,\n",
        "          y_combined,\n",
        "          \"train\",\n",
        "          tokenizer,\n",
        "          tuple_len,\n",
        "          batch_size=64,\n",
        "      )\n",
        "\n",
        "\n",
        "      test_loader = get_data_loaders(\n",
        "          df_combined,\n",
        "          y_combined,\n",
        "          \"test\",\n",
        "          tokenizer,\n",
        "          tuple_len,\n",
        "          batch_size=64,\n",
        "      )\n",
        "\n",
        "\"\"\"\n",
        "for image, x,y in test_loader:\n",
        "    for im in image:\n",
        "      pil_image = transforms.ToPILImage()(im)\n",
        "      display(pil_image)\n",
        "    break\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLyXwa83Pxaa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h8vt0iK9cg0L",
        "outputId": "9079f5c4-a6e7-4858-bbde-79e5096b7c18"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = get_model(\"resnet50\", \"gpt\", {}, {}, {})\n",
        "\n",
        "train_loader = get_data_loaders(\n",
        "    df_combined,\n",
        "    y_combined,\n",
        "    \"train\",\n",
        "    tokenizer,\n",
        "    tuple_len,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "\n",
        "test_loader = get_data_loaders(\n",
        "    df_combined,\n",
        "    y_combined,\n",
        "    \"test\",\n",
        "    tokenizer,\n",
        "    tuple_len,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "train(train_loader, test_loader, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Fld9ltJ92mRx",
        "outputId": "4bdee4b3-5bc2-4891-85bc-61877c77b900"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = get_model(\"convnext_tiny\", \"gpt\", {}, {}, {})\n",
        "\n",
        "train_loader = get_data_loaders(\n",
        "    df_combined,\n",
        "    y_combined,\n",
        "    \"train\",\n",
        "    tokenizer,\n",
        "    tuple_len,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "test_loader = get_data_loaders(\n",
        "    df_combined,\n",
        "    y_combined,\n",
        "    \"test\",\n",
        "    tokenizer,\n",
        "    tuple_len,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "train(train_loader, test_loader, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "gf7s5srR2vQL",
        "outputId": "62143b51-08bb-4c75-af19-8a9343cea760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters in total: 213.60M\n",
            "  - Encoder: 86.91M\n",
            "  - Decoder: 126.70M\n",
            "tensor([[338,  48, 305, 334, 326, 327, 307, 327, 336,  28,  17, 225, 260, 334,\n",
            "          43, 305, 334,  20, 336, 304, 334,   6,  16,   7, 336,  43, 305, 334,\n",
            "          20, 336, 304, 334,   6,  17,   7, 336,  43, 305, 334,  20, 336, 304,\n",
            "         334,   6,  18,   7, 336, 336, 176, 260, 334, 321, 336,   9, 260, 334,\n",
            "         100, 334, 321, 336, 336, 238, 339, 339, 339, 339, 339, 339, 339, 339,\n",
            "         339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339,\n",
            "         339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339,\n",
            "         339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339,\n",
            "         339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339,\n",
            "         339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339,\n",
            "         339, 339, 339, 339, 339, 339, 339, 339, 339, 339, 339]]) tensor([[ 48, 305, 334, 326, 327, 307, 327, 336,  28,  17, 225, 260, 334,  43,\n",
            "         305, 334,  20, 336, 304, 334,   6,  16,   7, 336,  43, 305, 334,  20,\n",
            "         336, 304, 334,   6,  17,   7, 336,  43, 305, 334,  20, 336, 304, 334,\n",
            "           6,  18,   7, 336, 336, 176, 260, 334, 321, 336,   9, 260, 334, 100,\n",
            "         334, 321, 336, 336, 238,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m      3\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m get_data_loaders(\n\u001b[1;32m      4\u001b[0m     df_combined,\n\u001b[1;32m      5\u001b[0m     y_combined,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# test_loader = get_data_loaders(\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     df_combined,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     y_combined,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     batch_size=10,\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/cwd/classes/gt-y3/cs4644-dl/proj/latexify1.0/src/train.py:122\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, test_loader, model, tokenizer, num_epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    121\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 122\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# ==== Analysis ====\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# accuracy\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/dl/lib64/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/dl/lib64/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/dl/lib64/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model, tokenizer = get_model(\"swin_v2_b\", \"transformer\", {}, {\"dropout\": 0.0}, {})\n",
        "\n",
        "train_loader = get_data_loaders(\n",
        "    df_combined,\n",
        "    y_combined,\n",
        "    \"train\",\n",
        "    tokenizer,\n",
        "    tuple_len,\n",
        "    batch_size=1,\n",
        ")\n",
        "\n",
        "test_loader = get_data_loaders(\n",
        "    df_combined,\n",
        "    y_combined,\n",
        "    \"test\",\n",
        "    tokenizer,\n",
        "    tuple_len,\n",
        "    batch_size=10,\n",
        ")\n",
        "\n",
        "train(train_loader, None, model, tokenizer, num_epochs=40)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
